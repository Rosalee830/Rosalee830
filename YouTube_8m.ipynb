{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YouTube-8m.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1D91AB60ggq-YfwDBPG_1lt2tyfW0oF6C",
      "authorship_tag": "ABX9TyMZGeInqQGT9M9lrjEG1n61",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rosalee830/Rosalee830/blob/main/YouTube_8m.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0Vm9FWhoiXz"
      },
      "source": [
        "import os\n",
        "import tempfile\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np # linear algebra\n",
        "import tensorflow as tf\n",
        "\n",
        "tmpdir = tempfile.mkdtemp()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilyiNMhToy2U"
      },
      "source": [
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "for device in physical_devices:\n",
        "  tf.config.experimental.set_memory_growth(device, True)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRSgPaDRo3i5",
        "outputId": "bed7019c-45de-42b8-a140-0e3eb386c513"
      },
      "source": [
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import seaborn as sns\n",
        "from IPython.display import YouTubeVideo\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install chart-studio\n",
        "import chart_studio.plotly as py\n",
        "import os\n",
        "print(os.listdir(\"/YouTube-8m\"))\n",
        "# video level feature file\n",
        "print(os.listdir(\"/YouTube-8m/video\"))\n",
        "# frame level features file\n",
        "print(os.listdir(\"/YouTube-8m/frame\"))\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chart-studio in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from chart-studio) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from chart-studio) (2.23.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from chart-studio) (1.3.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from chart-studio) (4.4.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio) (1.24.3)\n",
            "['.ipynb_checkpoints', 'frame', 'video']\n",
            "['train01.tfrecord', 'train00.tfrecord']\n",
            "['train01.tfrecord', 'train00.tfrecord']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCp437G8L1oa"
      },
      "source": [
        "# keras imports\n",
        "from keras.layers import Dense, Input, LSTM, Dropout, Bidirectional\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.models import load_model\n",
        "from keras.models import Model\n",
        "import operator\n",
        "import time \n",
        "import gc\n",
        "import os"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RsnhP6kS-vH"
      },
      "source": [
        "Creating training and dev set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjPb7G2xTA6k"
      },
      "source": [
        "def create_train_dev_dataset(video_rgb, video_audio, frame_rgb, frame_audio, labels):\n",
        "    \"\"\"\n",
        "    Method to created training and validation data\n",
        "    \"\"\"\n",
        "    shuffle_indices = np.random.permutation(np.arange(len(labels)))\n",
        "    video_rgb_shuffled = video_rgb[shuffle_indices]\n",
        "    video_audio_shuffled = video_audio[shuffle_indices]\n",
        "    frame_rgb_shuffled = frame_rgb[shuffle_indices]\n",
        "    frame_audio_shuffled = frame_audio[shuffle_indices]\n",
        "    labels_shuffled = labels[shuffle_indices]\n",
        "\n",
        "    dev_idx = max(1, int(len(labels_shuffled) * validation_split_ratio))\n",
        "\n",
        "    del video_rgb\n",
        "    del video_audio\n",
        "    del frame_rgb\n",
        "    del frame_audio\n",
        "    gc.collect()\n",
        "\n",
        "    train_video_rgb, val_video_rgb = video_rgb_shuffled[:-dev_idx], video_rgb_shuffled[-dev_idx:]\n",
        "    train_video_audio, val_video_audio = video_audio_shuffled[:-dev_idx], video_audio_shuffled[-dev_idx:]\n",
        "    \n",
        "    train_frame_rgb, val_frame_rgb = frame_rgb_shuffled[:-dev_idx], frame_rgb_shuffled[-dev_idx:]\n",
        "    train_frame_audio, val_frame_audio = frame_audio_shuffled[:-dev_idx], frame_audio_shuffled[-dev_idx:]\n",
        "    \n",
        "    train_labels, val_labels = labels_shuffled[:-dev_idx], labels_shuffled[-dev_idx:]\n",
        "    \n",
        "    del video_rgb_shuffled, video_audio_shuffled, frame_rgb_shuffled, frame_audio_shuffled, labels_shuffled\n",
        "    gc.collect()\n",
        "    \n",
        "    return (train_video_rgb, train_video_audio, train_frame_rgb, train_frame_audio, train_labels, val_video_rgb, val_video_audio, \n",
        "            val_frame_rgb, val_frame_audio, val_labels)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90_gd1LYWDR8"
      },
      "source": [
        "Defining Model parameters and creating architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuTI6pX6WEh7"
      },
      "source": [
        "max_frame_rgb_sequence_length = 10\n",
        "frame_rgb_embedding_size = 1024\n",
        "\n",
        "max_frame_audio_sequence_length = 10\n",
        "frame_audio_embedding_size = 128\n",
        "\n",
        "number_dense_units = 1000\n",
        "number_lstm_units = 100\n",
        "rate_drop_lstm = 0.2\n",
        "rate_drop_dense = 0.2\n",
        "activation_function='relu'\n",
        "validation_split_ratio = 0.2\n",
        "label_feature_size = 10\n",
        "\n",
        "def create_model(video_rgb, video_audio, frame_rgb, frame_audio, labels):\n",
        "    \"\"\"Create and store best model at `checkpoint` path ustilising bi-lstm layer for frame level data of videos\"\"\"\n",
        "    train_video_rgb, train_video_audio, train_frame_rgb, train_frame_audio, train_labels, val_video_rgb, val_video_audio, val_frame_rgb, val_frame_audio, val_labels = create_train_dev_dataset(video_rgb, video_audio, frame_rgb, frame_audio, labels) \n",
        "    \n",
        "    # Creating 2 bi-lstm layer, one for rgb and other for audio level data\n",
        "    lstm_layer_1 = Bidirectional(LSTM(number_lstm_units, dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm))\n",
        "    lstm_layer_2 = Bidirectional(LSTM(number_lstm_units, dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm))\n",
        "    \n",
        "    # creating input layer for frame-level data\n",
        "    frame_rgb_sequence_input = Input(shape=(max_frame_rgb_sequence_length, frame_rgb_embedding_size), dtype='float32')\n",
        "    frame_audio_sequence_input = Input(shape=(max_frame_audio_sequence_length, frame_audio_embedding_size), dtype='float32')\n",
        "    \n",
        "    frame_x1 = lstm_layer_1(frame_rgb_sequence_input)\n",
        "    frame_x2 = lstm_layer_2(frame_audio_sequence_input)\n",
        "    \n",
        "    # creating input layer for video-level data\n",
        "    video_rgb_input = Input(shape=(video_rgb.shape[1],))\n",
        "    video_rgb_dense = Dense(int(number_dense_units/2), activation=activation_function)(video_rgb_input)\n",
        "    \n",
        "    video_audio_input = Input(shape=(video_audio.shape[1],))\n",
        "    video_audio_dense = Dense(int(number_dense_units/2), activation=activation_function)(video_audio_input)\n",
        "    \n",
        "    # merging frame-level bi-lstm output and later passed to dense layer by applying batch-normalisation and dropout\n",
        "    merged_frame = concatenate([frame_x1, frame_x2])\n",
        "    merged_frame = BatchNormalization()(merged_frame)\n",
        "    merged_frame = Dropout(rate_drop_dense)(merged_frame)\n",
        "    merged_frame_dense = Dense(int(number_dense_units/2), activation=activation_function)(merged_frame)\n",
        "    \n",
        "    # merging video-level dense layer output\n",
        "    merged_video = concatenate([video_rgb_dense, video_audio_dense])\n",
        "    merged_video = BatchNormalization()(merged_video)\n",
        "    merged_video = Dropout(rate_drop_dense)(merged_video)\n",
        "    merged_video_dense = Dense(int(number_dense_units/2), activation=activation_function)(merged_video)\n",
        "    \n",
        "    # merging frame-level and video-level dense layer output\n",
        "    merged = concatenate([merged_frame_dense, merged_video_dense])\n",
        "    merged = BatchNormalization()(merged)\n",
        "    merged = Dropout(rate_drop_dense)(merged)\n",
        "     \n",
        "    merged = Dense(number_dense_units, activation=activation_function)(merged)\n",
        "    merged = BatchNormalization()(merged)\n",
        "    merged = Dropout(rate_drop_dense)(merged)\n",
        "    preds = Dense(label_feature_size, activation='sigmoid')(merged)\n",
        "    \n",
        "    model = Model(inputs=[frame_rgb_sequence_input, frame_audio_sequence_input, video_rgb_input, video_audio_input], outputs=preds)\n",
        "    print(model.summary())\n",
        "    model.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc'])\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "    \n",
        "    STAMP = 'lstm_%d_%d_%.2f_%.2f' % (number_lstm_units, number_dense_units, rate_drop_lstm, rate_drop_dense)\n",
        "\n",
        "    checkpoint_dir = 'checkpoints/' + str(int(time.time())) + '/'\n",
        "\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "\n",
        "    bst_model_path = checkpoint_dir + STAMP + '.h5'\n",
        "    model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=False)\n",
        "    tensorboard = TensorBoard(log_dir=checkpoint_dir + \"logs/{}\".format(time.time()))\n",
        "  \n",
        "    model.fit([train_frame_rgb, train_frame_audio, train_video_rgb, train_video_audio], train_labels,\n",
        "              validation_data=([val_frame_rgb, val_frame_audio, val_video_rgb, val_video_audio], val_labels),\n",
        "              epochs=200, batch_size=64, shuffle=True, callbacks=[early_stopping, model_checkpoint, tensorboard])    \n",
        "    return model"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gddl6Fv1W2Xd"
      },
      "source": [
        "Creating random data set for training \n",
        "\n",
        "Here I am creating a sample dataset of same size and dimension of training sample and will use it to train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xqE7RBZXTLG"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "sample_length = 1000\n",
        "\n",
        "video_rgb = np.random.rand(sample_length, 1024)\n",
        "video_audio = np.random.rand(sample_length, 128)\n",
        "\n",
        "frame_rgb = np.random.rand(sample_length, 10, 1024)\n",
        "frame_audio = np.random.rand(sample_length, 10, 128)\n",
        "\n",
        "# Here I have considered that I have only 10 labels.\n",
        "labels = np.zeros([sample_length,10])\n",
        "for i in range(len(labels)):\n",
        "    j = random.randint(0,9)\n",
        "    labels[i][j] = 1 "
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDpN1oTVa9SG"
      },
      "source": [
        "Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-_8gKhSbBQn",
        "outputId": "f1066231-6f96-489f-bc26-61bee0dfc949"
      },
      "source": [
        "model = create_model(video_rgb, video_audio, frame_rgb, frame_audio, labels)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            [(None, 10, 1024)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_10 (InputLayer)           [(None, 10, 128)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_11 (InputLayer)           [(None, 1024)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_12 (InputLayer)           [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_4 (Bidirectional) (None, 200)          900000      input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_5 (Bidirectional) (None, 200)          183200      input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 500)          512500      input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 500)          64500       input_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 400)          0           bidirectional_4[0][0]            \n",
            "                                                                 bidirectional_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 1000)         0           dense_12[0][0]                   \n",
            "                                                                 dense_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 400)          1600        concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 1000)         4000        concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 400)          0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 1000)         0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 500)          200500      dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_15 (Dense)                (None, 500)          500500      dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 1000)         0           dense_14[0][0]                   \n",
            "                                                                 dense_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 1000)         4000        concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 1000)         0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 1000)         1001000     dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 1000)         4000        dense_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 1000)         0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 10)           10010       dropout_11[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 3,385,810\n",
            "Trainable params: 3,379,010\n",
            "Non-trainable params: 6,800\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "13/13 [==============================] - 18s 507ms/step - loss: 0.9053 - acc: 0.1125 - val_loss: 0.6599 - val_acc: 0.0650\n",
            "Epoch 2/200\n",
            "13/13 [==============================] - 4s 296ms/step - loss: 0.7262 - acc: 0.3212 - val_loss: 0.6159 - val_acc: 0.1300\n",
            "Epoch 3/200\n",
            "13/13 [==============================] - 4s 302ms/step - loss: 0.6106 - acc: 0.5300 - val_loss: 0.5358 - val_acc: 0.1100\n",
            "Epoch 4/200\n",
            "13/13 [==============================] - 4s 305ms/step - loss: 0.4935 - acc: 0.6725 - val_loss: 0.4809 - val_acc: 0.0950\n",
            "Epoch 5/200\n",
            "13/13 [==============================] - 4s 297ms/step - loss: 0.3931 - acc: 0.7950 - val_loss: 0.4066 - val_acc: 0.1250\n",
            "Epoch 6/200\n",
            "13/13 [==============================] - 4s 302ms/step - loss: 0.2981 - acc: 0.8775 - val_loss: 0.3675 - val_acc: 0.1300\n",
            "Epoch 7/200\n",
            "13/13 [==============================] - 4s 308ms/step - loss: 0.2214 - acc: 0.9200 - val_loss: 0.3538 - val_acc: 0.1450\n",
            "Epoch 8/200\n",
            "13/13 [==============================] - 4s 307ms/step - loss: 0.1674 - acc: 0.9575 - val_loss: 0.3506 - val_acc: 0.1250\n",
            "Epoch 9/200\n",
            "13/13 [==============================] - 4s 296ms/step - loss: 0.1271 - acc: 0.9812 - val_loss: 0.3481 - val_acc: 0.1400\n",
            "Epoch 10/200\n",
            "13/13 [==============================] - 4s 300ms/step - loss: 0.0991 - acc: 0.9875 - val_loss: 0.3576 - val_acc: 0.1400\n",
            "Epoch 11/200\n",
            "13/13 [==============================] - 4s 290ms/step - loss: 0.0769 - acc: 0.9925 - val_loss: 0.3699 - val_acc: 0.1400\n",
            "Epoch 12/200\n",
            "13/13 [==============================] - 4s 288ms/step - loss: 0.0613 - acc: 0.9937 - val_loss: 0.3775 - val_acc: 0.1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNsu_uJFjNAo"
      },
      "source": [
        "#As the model trains, the loss and accuracy metrics are displayed. This model reaches an accuracy of about 0.99 (or 99%) on the training data.#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6-8ZjMsjiDz",
        "outputId": "b1e5cb20-6fb4-4e37-cfb2-404f3e207f66"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            [(None, 10, 1024)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_10 (InputLayer)           [(None, 10, 128)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_11 (InputLayer)           [(None, 1024)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_12 (InputLayer)           [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_4 (Bidirectional) (None, 200)          900000      input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_5 (Bidirectional) (None, 200)          183200      input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 500)          512500      input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 500)          64500       input_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 400)          0           bidirectional_4[0][0]            \n",
            "                                                                 bidirectional_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 1000)         0           dense_12[0][0]                   \n",
            "                                                                 dense_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 400)          1600        concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 1000)         4000        concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 400)          0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 1000)         0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 500)          200500      dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_15 (Dense)                (None, 500)          500500      dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 1000)         0           dense_14[0][0]                   \n",
            "                                                                 dense_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 1000)         4000        concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 1000)         0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 1000)         1001000     dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 1000)         4000        dense_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 1000)         0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 10)           10010       dropout_11[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 3,385,810\n",
            "Trainable params: 3,379,010\n",
            "Non-trainable params: 6,800\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3MJYM9ReGjt"
      },
      "source": [
        "Testing with created random test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n916N5qPeHyI",
        "outputId": "f0a8246c-7035-4a38-c2d9-c9337b2f6bda"
      },
      "source": [
        "test_video_rgb = np.random.rand(1, 1024)\n",
        "test_video_audio = np.random.rand(1, 128)\n",
        "\n",
        "test_frame_rgb = np.random.rand(1, 10, 1024)\n",
        "test_frame_audio = np.random.rand(1, 10, 128)\n",
        "\n",
        "preds = list(model.predict([test_frame_rgb, test_frame_audio, test_video_rgb, test_video_audio], verbose=1).ravel())\n",
        "index, value = max(enumerate(preds), key=operator.itemgetter(1))\n",
        "print(\"Predicted Label - %s with probability - %s\" % (str(index), str(value)))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "Predicted Label - 5 with probability - 0.16813391\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iojjeQGekFkM"
      },
      "source": [
        "Ploting the perfomance of model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZuJrrhwfyrF",
        "outputId": "0bfdb033-113b-48e5-c45c-546790ee5977"
      },
      "source": [
        "testPredict = model.predict([test_frame_rgb, test_frame_audio, test_video_rgb, test_video_audio], verbose=1).ravel()\n",
        "trainPredict = model.predict([frame_rgb, frame_audio, video_rgb, video_audio], verbose=1).ravel()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 34ms/step\n",
            "32/32 [==============================] - 1s 44ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "GoXOVViCdmGu",
        "outputId": "fd6879fa-d6f3-4ed0-bd60-10efd1eb16ab"
      },
      "source": [
        "import numpy as np\n",
        "def prediction(model):\n",
        "    prediction = model.predict(np.logical_and \"test_frame_rgb\", \"test_frame_audio\", \"test_video_rgb\", \"test_video_audio\")\n",
        "    return prediction\n",
        "prediction_bilstm = prediction(model)\n",
        "# Define a function to calculate MAE and RMSE\n",
        "def evaluate_prediction(predictions, actual, model):\n",
        "    errors = predictions - actual\n",
        "    mse = np.square(errors).mean()\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = np.abs(errors).mean()\n",
        "\n",
        "    print('Mean Absolute Error: {:.4f}'.format(mae))\n",
        "    print('Root Mean Square Error: {:.4f}'.format(rmse))\n",
        "    print('')\n",
        "evaluate_prediction(prediction_bilstm, y_test, 'Bidirectional LSTM')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-57-c83866717290>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    prediction = model.predict(np.logical_and \"test_frame_rgb\", \"test_frame_audio\", \"test_video_rgb\", \"test_video_audio\")\u001b[0m\n\u001b[0m                                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}