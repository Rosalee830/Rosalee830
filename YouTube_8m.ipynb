{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YouTube-8m.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1D91AB60ggq-YfwDBPG_1lt2tyfW0oF6C",
      "authorship_tag": "ABX9TyPC1QrJLWjj1IqQsH7b1pVE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rosalee830/Rosalee830/blob/main/YouTube_8m.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0Vm9FWhoiXz"
      },
      "source": [
        "import os\n",
        "import tempfile\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np # linear algebra\n",
        "import tensorflow as tf\n",
        "\n",
        "tmpdir = tempfile.mkdtemp()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilyiNMhToy2U"
      },
      "source": [
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "for device in physical_devices:\n",
        "  tf.config.experimental.set_memory_growth(device, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRSgPaDRo3i5",
        "outputId": "a563fa8e-794e-436c-871c-23fcdb860905"
      },
      "source": [
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import seaborn as sns\n",
        "from IPython.display import YouTubeVideo\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install chart-studio\n",
        "import chart_studio.plotly as py\n",
        "import os\n",
        "print(os.listdir(\"/YouTube-8m\"))\n",
        "# video level feature file\n",
        "print(os.listdir(\"/YouTube-8m/video\"))\n",
        "# frame level features file\n",
        "print(os.listdir(\"/YouTube-8m/frame\"))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chart-studio in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from chart-studio) (2.23.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from chart-studio) (1.3.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from chart-studio) (4.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from chart-studio) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio) (2021.5.30)\n",
            "['frame', 'video', '.ipynb_checkpoints']\n",
            "['train01.tfrecord', 'train00.tfrecord']\n",
            "['train01.tfrecord', 'train00.tfrecord']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCp437G8L1oa"
      },
      "source": [
        "# keras imports\n",
        "from keras.layers import Dense, Input, LSTM, Dropout, Bidirectional\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.models import load_model\n",
        "from keras.models import Model\n",
        "import operator\n",
        "import time \n",
        "import gc\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RsnhP6kS-vH"
      },
      "source": [
        "Creating training and validate dataset by combining video_rgb, video_audio, frame_rgb, frame_audio and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjPb7G2xTA6k"
      },
      "source": [
        "def create_train_dev_dataset(video_rgb, video_audio, frame_rgb, frame_audio, labels):\n",
        "    \"\"\"\n",
        "    Method to created training and validation data\n",
        "    \"\"\"\n",
        "    shuffle_indices = np.random.permutation(np.arange(len(labels)))\n",
        "    video_rgb_shuffled = video_rgb[shuffle_indices]\n",
        "    video_audio_shuffled = video_audio[shuffle_indices]\n",
        "    frame_rgb_shuffled = frame_rgb[shuffle_indices]\n",
        "    frame_audio_shuffled = frame_audio[shuffle_indices]\n",
        "    labels_shuffled = labels[shuffle_indices]\n",
        "\n",
        "    dev_idx = max(1, int(len(labels_shuffled) * validation_split_ratio))\n",
        "\n",
        "    del video_rgb\n",
        "    del video_audio\n",
        "    del frame_rgb\n",
        "    del frame_audio\n",
        "    gc.collect()\n",
        "\n",
        "    train_video_rgb, val_video_rgb = video_rgb_shuffled[:-dev_idx], video_rgb_shuffled[-dev_idx:]\n",
        "    train_video_audio, val_video_audio = video_audio_shuffled[:-dev_idx], video_audio_shuffled[-dev_idx:]\n",
        "    \n",
        "    train_frame_rgb, val_frame_rgb = frame_rgb_shuffled[:-dev_idx], frame_rgb_shuffled[-dev_idx:]\n",
        "    train_frame_audio, val_frame_audio = frame_audio_shuffled[:-dev_idx], frame_audio_shuffled[-dev_idx:]\n",
        "    \n",
        "    train_labels, val_labels = labels_shuffled[:-dev_idx], labels_shuffled[-dev_idx:]\n",
        "    \n",
        "    del video_rgb_shuffled, video_audio_shuffled, frame_rgb_shuffled, frame_audio_shuffled, labels_shuffled\n",
        "    gc.collect()\n",
        "    \n",
        "    return (train_video_rgb, train_video_audio, train_frame_rgb, train_frame_audio, train_labels, val_video_rgb, val_video_audio, \n",
        "            val_frame_rgb, val_frame_audio, val_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90_gd1LYWDR8"
      },
      "source": [
        "Defining Model parameters, creating architecture and using checkpoint to store the best model and use it for future"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuTI6pX6WEh7"
      },
      "source": [
        "max_frame_rgb_sequence_length = 10\n",
        "frame_rgb_embedding_size = 1024\n",
        "\n",
        "max_frame_audio_sequence_length = 10\n",
        "frame_audio_embedding_size = 128\n",
        "\n",
        "number_dense_units = 1000\n",
        "number_lstm_units = 100\n",
        "rate_drop_lstm = 0.2\n",
        "rate_drop_dense = 0.2\n",
        "activation_function='relu'\n",
        "validation_split_ratio = 0.2\n",
        "label_feature_size = 10\n",
        "\n",
        "def create_model(video_rgb, video_audio, frame_rgb, frame_audio, labels):\n",
        "    \"\"\"Create and store best model at `checkpoint` path ustilising bi-lstm layer for frame level data of videos\"\"\"\n",
        "    train_video_rgb, train_video_audio, train_frame_rgb, train_frame_audio, train_labels, val_video_rgb, val_video_audio, val_frame_rgb, val_frame_audio, val_labels = create_train_dev_dataset(video_rgb, video_audio, frame_rgb, frame_audio, labels) \n",
        "    \n",
        "    # Creating 2 bi-lstm layer, one for rgb and other for audio level data\n",
        "    lstm_layer_1 = Bidirectional(LSTM(number_lstm_units, dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm))\n",
        "    lstm_layer_2 = Bidirectional(LSTM(number_lstm_units, dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm))\n",
        "    \n",
        "    # creating input layer for frame-level data\n",
        "    frame_rgb_sequence_input = Input(shape=(max_frame_rgb_sequence_length, frame_rgb_embedding_size), dtype='float32')\n",
        "    frame_audio_sequence_input = Input(shape=(max_frame_audio_sequence_length, frame_audio_embedding_size), dtype='float32')\n",
        "    \n",
        "    frame_x1 = lstm_layer_1(frame_rgb_sequence_input)\n",
        "    frame_x2 = lstm_layer_2(frame_audio_sequence_input)\n",
        "    \n",
        "    # creating input layer for video-level data\n",
        "    video_rgb_input = Input(shape=(video_rgb.shape[1],))\n",
        "    video_rgb_dense = Dense(int(number_dense_units/2), activation=activation_function)(video_rgb_input)\n",
        "    \n",
        "    video_audio_input = Input(shape=(video_audio.shape[1],))\n",
        "    video_audio_dense = Dense(int(number_dense_units/2), activation=activation_function)(video_audio_input)\n",
        "    \n",
        "    # merging frame-level bi-lstm output and later passed to dense layer by applying batch-normalisation and dropout\n",
        "    merged_frame = concatenate([frame_x1, frame_x2])\n",
        "    merged_frame = BatchNormalization()(merged_frame)\n",
        "    merged_frame = Dropout(rate_drop_dense)(merged_frame)\n",
        "    merged_frame_dense = Dense(int(number_dense_units/2), activation=activation_function)(merged_frame)\n",
        "    \n",
        "    # merging video-level dense layer output\n",
        "    merged_video = concatenate([video_rgb_dense, video_audio_dense])\n",
        "    merged_video = BatchNormalization()(merged_video)\n",
        "    merged_video = Dropout(rate_drop_dense)(merged_video)\n",
        "    merged_video_dense = Dense(int(number_dense_units/2), activation=activation_function)(merged_video)\n",
        "    \n",
        "    # merging frame-level and video-level dense layer output\n",
        "    merged = concatenate([merged_frame_dense, merged_video_dense])\n",
        "    merged = BatchNormalization()(merged)\n",
        "    merged = Dropout(rate_drop_dense)(merged)\n",
        "     \n",
        "    merged = Dense(number_dense_units, activation=activation_function)(merged)\n",
        "    merged = BatchNormalization()(merged)\n",
        "    merged = Dropout(rate_drop_dense)(merged)\n",
        "    preds = Dense(label_feature_size, activation='sigmoid')(merged)\n",
        "    \n",
        "    model = Model(inputs=[frame_rgb_sequence_input, frame_audio_sequence_input, video_rgb_input, video_audio_input], outputs=preds)\n",
        "    print(model.summary())\n",
        "    model.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc'])\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "    \n",
        "    STAMP = 'lstm_%d_%d_%.2f_%.2f' % (number_lstm_units, number_dense_units, rate_drop_lstm, rate_drop_dense)\n",
        "\n",
        "    checkpoint_dir = 'checkpoints/' + str(int(time.time())) + '/'\n",
        "\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "\n",
        "    bst_model_path = checkpoint_dir + STAMP + '.h5'\n",
        "    model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=False)\n",
        "    tensorboard = TensorBoard(log_dir=checkpoint_dir + \"logs/{}\".format(time.time()))\n",
        "  \n",
        "    model.fit([train_frame_rgb, train_frame_audio, train_video_rgb, train_video_audio], train_labels,\n",
        "              validation_data=([val_frame_rgb, val_frame_audio, val_video_rgb, val_video_audio], val_labels),\n",
        "              epochs=200, batch_size=64, shuffle=False, callbacks=[early_stopping, model_checkpoint, tensorboard])    \n",
        "    return model\n",
        "\n",
        "\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gddl6Fv1W2Xd"
      },
      "source": [
        "Creating random data set for training \n",
        "\n",
        "Here I am creating a sample dataset of same size and dimension of training sample and will use it to train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xqE7RBZXTLG"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "sample_length = 1000\n",
        "\n",
        "video_rgb = np.random.rand(sample_length, 1024)\n",
        "video_audio = np.random.rand(sample_length, 128)\n",
        "\n",
        "frame_rgb = np.random.rand(sample_length, 10, 1024)\n",
        "frame_audio = np.random.rand(sample_length, 10, 128)\n",
        "\n",
        "# Here I have considered that I have only 10 labels.\n",
        "labels = np.zeros([sample_length,10])\n",
        "for i in range(len(labels)):\n",
        "    j = random.randint(0,9)\n",
        "    labels[i][j] = 1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDpN1oTVa9SG"
      },
      "source": [
        "Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-_8gKhSbBQn",
        "outputId": "de6617cd-e07f-45d2-ff39-0269dbf8a73d"
      },
      "source": [
        "model = create_model(video_rgb, video_audio, frame_rgb, frame_audio, labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            [(None, 10, 1024)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_10 (InputLayer)           [(None, 10, 128)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_11 (InputLayer)           [(None, 1024)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_12 (InputLayer)           [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_4 (Bidirectional) (None, 200)          900000      input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_5 (Bidirectional) (None, 200)          183200      input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 500)          512500      input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 500)          64500       input_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 400)          0           bidirectional_4[0][0]            \n",
            "                                                                 bidirectional_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 1000)         0           dense_12[0][0]                   \n",
            "                                                                 dense_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 400)          1600        concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 1000)         4000        concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 400)          0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 1000)         0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 500)          200500      dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_15 (Dense)                (None, 500)          500500      dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 1000)         0           dense_14[0][0]                   \n",
            "                                                                 dense_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 1000)         4000        concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 1000)         0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 1000)         1001000     dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 1000)         4000        dense_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 1000)         0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 10)           10010       dropout_11[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 3,385,810\n",
            "Trainable params: 3,379,010\n",
            "Non-trainable params: 6,800\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "13/13 [==============================] - 17s 489ms/step - loss: 0.9138 - acc: 0.0812 - val_loss: 0.6545 - val_acc: 0.1350\n",
            "Epoch 2/200\n",
            "13/13 [==============================] - 4s 278ms/step - loss: 0.7274 - acc: 0.3175 - val_loss: 0.5822 - val_acc: 0.1450\n",
            "Epoch 3/200\n",
            "13/13 [==============================] - 4s 294ms/step - loss: 0.6034 - acc: 0.5487 - val_loss: 0.5206 - val_acc: 0.1150\n",
            "Epoch 4/200\n",
            "13/13 [==============================] - 4s 291ms/step - loss: 0.4966 - acc: 0.6862 - val_loss: 0.4437 - val_acc: 0.1100\n",
            "Epoch 5/200\n",
            "13/13 [==============================] - 4s 294ms/step - loss: 0.3958 - acc: 0.7887 - val_loss: 0.3925 - val_acc: 0.1250\n",
            "Epoch 6/200\n",
            "13/13 [==============================] - 4s 292ms/step - loss: 0.2949 - acc: 0.8725 - val_loss: 0.3440 - val_acc: 0.1350\n",
            "Epoch 7/200\n",
            "13/13 [==============================] - 4s 293ms/step - loss: 0.2199 - acc: 0.9325 - val_loss: 0.3366 - val_acc: 0.1400\n",
            "Epoch 8/200\n",
            "13/13 [==============================] - 4s 283ms/step - loss: 0.1615 - acc: 0.9600 - val_loss: 0.3360 - val_acc: 0.1350\n",
            "Epoch 9/200\n",
            "13/13 [==============================] - 4s 289ms/step - loss: 0.1219 - acc: 0.9762 - val_loss: 0.3449 - val_acc: 0.1350\n",
            "Epoch 10/200\n",
            "13/13 [==============================] - 4s 290ms/step - loss: 0.0937 - acc: 0.9912 - val_loss: 0.3592 - val_acc: 0.1700\n",
            "Epoch 11/200\n",
            "13/13 [==============================] - 4s 281ms/step - loss: 0.0731 - acc: 0.9975 - val_loss: 0.3730 - val_acc: 0.1400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNsu_uJFjNAo"
      },
      "source": [
        "#As the model trains, the loss and accuracy metrics are displayed. This model reaches an accuracy of about 0.99 (or 99%) on the training data.#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6-8ZjMsjiDz",
        "outputId": "d0630965-969b-47f1-fbbe-d5eeeb8ce81f"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 10, 1024)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 10, 128)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 1024)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 200)          900000      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 200)          183200      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 500)          512500      input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 500)          64500       input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 400)          0           bidirectional[0][0]              \n",
            "                                                                 bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 1000)         0           dense[0][0]                      \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 400)          1600        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 1000)         4000        concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 400)          0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 1000)         0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 500)          200500      dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 500)          500500      dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 1000)         0           dense_2[0][0]                    \n",
            "                                                                 dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 1000)         4000        concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 1000)         0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1000)         1001000     dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 1000)         4000        dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 1000)         0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 10)           10010       dropout_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 3,385,810\n",
            "Trainable params: 3,379,010\n",
            "Non-trainable params: 6,800\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3MJYM9ReGjt"
      },
      "source": [
        "Testing with created random test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n916N5qPeHyI",
        "outputId": "addcaa91-73b7-4df3-fa04-d92466e137c1"
      },
      "source": [
        "test_video_rgb = np.random.rand(1, 1024)\n",
        "test_video_audio = np.random.rand(1, 128)\n",
        "\n",
        "test_frame_rgb = np.random.rand(1, 10, 1024)\n",
        "test_frame_audio = np.random.rand(1, 10, 128)\n",
        "\n",
        "preds = list(model.predict([test_frame_rgb, test_frame_audio, test_video_rgb, test_video_audio], verbose=1).ravel())\n",
        "index, value = max(enumerate(preds), key=operator.itemgetter(1))\n",
        "print(\"Predicted Label - %s with probability - %s\" % (str(index), str(value)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 909ms/step\n",
            "Predicted Label - 5 with probability - 0.13874406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iojjeQGekFkM"
      },
      "source": [
        "Ploting the result and perfomance of model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFNxhIM3KpyA"
      },
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "model_img = plt.imread('model_plot.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "id": "28FRiGlfdGmp",
        "outputId": "202c5ef7-5852-4da8-88d0-b2d91f23d247"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "def fit_model(model):\n",
        "    early_stop = keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 3)\n",
        "    history = model.fit([frame_rgb, frame_audio, video_rgb, video_audio], labels, validation_split = 0.2, epochs=200, batch_size=64, shuffle=False, callbacks=[early_stop])    \n",
        "    return history\n",
        "history_bilstm = fit_model(model)\n",
        "\n",
        "  # Plot train loss and validation loss\n",
        "def plot_loss (history):\n",
        "    plt.figure(figsize = (10, 6))\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['Train loss', 'Validation loss'], loc='upper right')\n",
        "\n",
        "plot_loss (history_bilstm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "13/13 [==============================] - 4s 279ms/step - loss: 0.1490 - acc: 0.8188 - val_loss: 0.2136 - val_acc: 0.7150\n",
            "Epoch 2/200\n",
            "13/13 [==============================] - 4s 272ms/step - loss: 0.0879 - acc: 0.9200 - val_loss: 0.2142 - val_acc: 0.6700\n",
            "Epoch 3/200\n",
            "13/13 [==============================] - 4s 272ms/step - loss: 0.0600 - acc: 0.9862 - val_loss: 0.2050 - val_acc: 0.7100\n",
            "Epoch 4/200\n",
            "13/13 [==============================] - 4s 275ms/step - loss: 0.0475 - acc: 0.9987 - val_loss: 0.2069 - val_acc: 0.7050\n",
            "Epoch 5/200\n",
            "13/13 [==============================] - 4s 274ms/step - loss: 0.0345 - acc: 1.0000 - val_loss: 0.2104 - val_acc: 0.7250\n",
            "Epoch 6/200\n",
            "13/13 [==============================] - 4s 274ms/step - loss: 0.0287 - acc: 1.0000 - val_loss: 0.1987 - val_acc: 0.7400\n",
            "Epoch 7/200\n",
            "13/13 [==============================] - 4s 274ms/step - loss: 0.0252 - acc: 1.0000 - val_loss: 0.1878 - val_acc: 0.7550\n",
            "Epoch 8/200\n",
            "13/13 [==============================] - 4s 271ms/step - loss: 0.0203 - acc: 1.0000 - val_loss: 0.1915 - val_acc: 0.7450\n",
            "Epoch 9/200\n",
            "13/13 [==============================] - 4s 275ms/step - loss: 0.0173 - acc: 0.9987 - val_loss: 0.1952 - val_acc: 0.7400\n",
            "Epoch 10/200\n",
            "13/13 [==============================] - 4s 277ms/step - loss: 0.0136 - acc: 1.0000 - val_loss: 0.1942 - val_acc: 0.7400\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VluCo5M6avP"
      },
      "source": [
        " def ap_at_n(predictions, actuals, n=20, total_num_positives=None):\n",
        "    \"\"\"Calculate the non-interpolated average precision.\n",
        "    Args:\n",
        "      predictions: a numpy 1-D array storing the sparse prediction scores.\n",
        "      actuals: a numpy 1-D array storing the ground truth labels. Any value\n",
        "        larger than 0 will be treated as positives, otherwise as negatives.\n",
        "      n: the top n items to be considered in ap@n.\n",
        "      total_num_positives : (optionally) you can specify the number of total\n",
        "        positive in the list. If specified, it will be used in calculation.\n",
        "    Returns:\n",
        "      The non-interpolated average precision at n.\n",
        "      If n is larger than the length of the ranked list,\n",
        "      the average precision will be returned.\n",
        "    Raises:\n",
        "      ValueError: An error occurred when\n",
        "      1) the format of the input is not the numpy 1-D array;\n",
        "      2) the shape of predictions and actuals does not match;\n",
        "      3) the input n is not a positive integer.\n",
        "    \"\"\"\n",
        "    if len(predictions) != len(actuals):\n",
        "      raise ValueError(\"the shape of predictions and actuals does not match.\")\n",
        "\n",
        "    if n is not None:\n",
        "      if not isinstance(n, int) or n <= 0:\n",
        "        raise ValueError(\"n must be 'None' or a positive integer.\"\n",
        "                         \" It was '%s'.\" % n)\n",
        "\n",
        "    ap = 0.0\n",
        "\n",
        "    predictions = numpy.array(predictions)\n",
        "    actuals = numpy.array(actuals)\n",
        "\n",
        "    # add a shuffler to avoid overestimating the ap\n",
        "    predictions, actuals = AveragePrecisionCalculator._shuffle(\n",
        "        predictions, actuals)\n",
        "    sortidx = sorted(range(len(predictions)),\n",
        "                     key=lambda k: predictions[k],\n",
        "                     reverse=True)\n",
        "\n",
        "    if total_num_positives is None:\n",
        "      numpos = numpy.size(numpy.where(actuals > 0))\n",
        "    else:\n",
        "      numpos = total_num_positives\n",
        "\n",
        "    if numpos == 0:\n",
        "      return 0\n",
        "\n",
        "    if n is not None:\n",
        "      numpos = min(numpos, n)\n",
        "    delta_recall = 1.0 / numpos\n",
        "    poscount = 0.0\n",
        "\n",
        "    # calculate the ap\n",
        "    r = len(sortidx)\n",
        "    if n is not None:\n",
        "      r = min(r, n)\n",
        "    for i in range(r):\n",
        "      if actuals[sortidx[i]] > 0:\n",
        "        poscount += 1\n",
        "        ap += poscount / (i + 1) * delta_recall\n",
        "    return ap\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbut9GNKvFwN"
      },
      "source": [
        "from sklearn import metrics\n",
        "print(\"\")\n",
        "print(\"Confusion Matrix:\")\n",
        "confusion_matrix = metrics.confusion_matrix(labels, pred)\n",
        "print(confusion_matrix)\n",
        "normalised_confusion_matrix = np.array(confusion_matrix, dtype=np.float32)/np.sum(confusion_matrix)*100\n",
        "\n",
        "print(\"\")\n",
        "print(\"Confusion matrix (normalised to % of total test data):\")\n",
        "print(normalised_confusion_matrix)\n",
        "print(\"Note: training and testing data is not equally distributed amongst classes, \")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jd5nltcOppo"
      },
      "source": [
        "References:\n",
        "\n",
        "Exploration + Bi-LSTM Model, Amansrivastava"
      ]
    }
  ]
}