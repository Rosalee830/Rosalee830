{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YouTube-8m.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1D91AB60ggq-YfwDBPG_1lt2tyfW0oF6C",
      "authorship_tag": "ABX9TyMNkXLZEY5u4wW/W4N5k+84",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rosalee830/Rosalee830/blob/main/YouTube_8m.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0Vm9FWhoiXz"
      },
      "source": [
        "import os\n",
        "import tempfile\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np # linear algebra\n",
        "import tensorflow as tf\n",
        "\n",
        "tmpdir = tempfile.mkdtemp()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilyiNMhToy2U"
      },
      "source": [
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "for device in physical_devices:\n",
        "  tf.config.experimental.set_memory_growth(device, True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRSgPaDRo3i5",
        "outputId": "a7421163-acbb-417b-fdea-ec8a827a9255"
      },
      "source": [
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import seaborn as sns\n",
        "from IPython.display import YouTubeVideo\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install chart-studio\n",
        "import chart_studio.plotly as py\n",
        "import os\n",
        "print(os.listdir(\"/YouTube-8m\"))\n",
        "# video level feature file\n",
        "print(os.listdir(\"/YouTube-8m/video\"))\n",
        "# frame level features file\n",
        "print(os.listdir(\"/YouTube-8m/frame\"))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chart-studio\n",
            "  Downloading chart_studio-1.1.0-py3-none-any.whl (64 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████                           | 10 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30 kB 33.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 40 kB 37.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 51 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 61 kB 25.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 64 kB 3.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from chart-studio) (1.15.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from chart-studio) (4.4.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from chart-studio) (1.3.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from chart-studio) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio) (2.10)\n",
            "Installing collected packages: chart-studio\n",
            "Successfully installed chart-studio-1.1.0\n",
            "['frame', 'video', '.ipynb_checkpoints']\n",
            "['train01.tfrecord', 'train00.tfrecord']\n",
            "['train01.tfrecord', 'train00.tfrecord']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCp437G8L1oa"
      },
      "source": [
        "# keras imports\n",
        "from keras.layers import Dense, Input, LSTM, Dropout, Bidirectional\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.models import load_model\n",
        "from keras.models import Model\n",
        "import operator\n",
        "import time \n",
        "import gc\n",
        "import os"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RsnhP6kS-vH"
      },
      "source": [
        "Creating training and dev set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjPb7G2xTA6k"
      },
      "source": [
        "def create_train_dev_dataset(video_rgb, video_audio, frame_rgb, frame_audio, labels):\n",
        "    \"\"\"\n",
        "    Method to created training and validation data\n",
        "    \"\"\"\n",
        "    shuffle_indices = np.random.permutation(np.arange(len(labels)))\n",
        "    video_rgb_shuffled = video_rgb[shuffle_indices]\n",
        "    video_audio_shuffled = video_audio[shuffle_indices]\n",
        "    frame_rgb_shuffled = frame_rgb[shuffle_indices]\n",
        "    frame_audio_shuffled = frame_audio[shuffle_indices]\n",
        "    labels_shuffled = labels[shuffle_indices]\n",
        "\n",
        "    dev_idx = max(1, int(len(labels_shuffled) * validation_split_ratio))\n",
        "\n",
        "    del video_rgb\n",
        "    del video_audio\n",
        "    del frame_rgb\n",
        "    del frame_audio\n",
        "    gc.collect()\n",
        "\n",
        "    train_video_rgb, val_video_rgb = video_rgb_shuffled[:-dev_idx], video_rgb_shuffled[-dev_idx:]\n",
        "    train_video_audio, val_video_audio = video_audio_shuffled[:-dev_idx], video_audio_shuffled[-dev_idx:]\n",
        "    \n",
        "    train_frame_rgb, val_frame_rgb = frame_rgb_shuffled[:-dev_idx], frame_rgb_shuffled[-dev_idx:]\n",
        "    train_frame_audio, val_frame_audio = frame_audio_shuffled[:-dev_idx], frame_audio_shuffled[-dev_idx:]\n",
        "    \n",
        "    train_labels, val_labels = labels_shuffled[:-dev_idx], labels_shuffled[-dev_idx:]\n",
        "    \n",
        "    del video_rgb_shuffled, video_audio_shuffled, frame_rgb_shuffled, frame_audio_shuffled, labels_shuffled\n",
        "    gc.collect()\n",
        "    \n",
        "    return (train_video_rgb, train_video_audio, train_frame_rgb, train_frame_audio, train_labels, val_video_rgb, val_video_audio, \n",
        "            val_frame_rgb, val_frame_audio, val_labels)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90_gd1LYWDR8"
      },
      "source": [
        "Defining Model parameters and creating architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuTI6pX6WEh7"
      },
      "source": [
        "max_frame_rgb_sequence_length = 10\n",
        "frame_rgb_embedding_size = 1024\n",
        "\n",
        "max_frame_audio_sequence_length = 10\n",
        "frame_audio_embedding_size = 128\n",
        "\n",
        "number_dense_units = 1000\n",
        "number_lstm_units = 100\n",
        "rate_drop_lstm = 0.2\n",
        "rate_drop_dense = 0.2\n",
        "activation_function='relu'\n",
        "validation_split_ratio = 0.2\n",
        "label_feature_size = 10\n",
        "\n",
        "def create_model(video_rgb, video_audio, frame_rgb, frame_audio, labels):\n",
        "    \"\"\"Create and store best model at `checkpoint` path ustilising bi-lstm layer for frame level data of videos\"\"\"\n",
        "    train_video_rgb, train_video_audio, train_frame_rgb, train_frame_audio, train_labels, val_video_rgb, val_video_audio, val_frame_rgb, val_frame_audio, val_labels = create_train_dev_dataset(video_rgb, video_audio, frame_rgb, frame_audio, labels) \n",
        "    \n",
        "    # Creating 2 bi-lstm layer, one for rgb and other for audio level data\n",
        "    lstm_layer_1 = Bidirectional(LSTM(number_lstm_units, dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm))\n",
        "    lstm_layer_2 = Bidirectional(LSTM(number_lstm_units, dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm))\n",
        "    \n",
        "    # creating input layer for frame-level data\n",
        "    frame_rgb_sequence_input = Input(shape=(max_frame_rgb_sequence_length, frame_rgb_embedding_size), dtype='float32')\n",
        "    frame_audio_sequence_input = Input(shape=(max_frame_audio_sequence_length, frame_audio_embedding_size), dtype='float32')\n",
        "    \n",
        "    frame_x1 = lstm_layer_1(frame_rgb_sequence_input)\n",
        "    frame_x2 = lstm_layer_2(frame_audio_sequence_input)\n",
        "    \n",
        "    # creating input layer for video-level data\n",
        "    video_rgb_input = Input(shape=(video_rgb.shape[1],))\n",
        "    video_rgb_dense = Dense(int(number_dense_units/2), activation=activation_function)(video_rgb_input)\n",
        "    \n",
        "    video_audio_input = Input(shape=(video_audio.shape[1],))\n",
        "    video_audio_dense = Dense(int(number_dense_units/2), activation=activation_function)(video_audio_input)\n",
        "    \n",
        "    # merging frame-level bi-lstm output and later passed to dense layer by applying batch-normalisation and dropout\n",
        "    merged_frame = concatenate([frame_x1, frame_x2])\n",
        "    merged_frame = BatchNormalization()(merged_frame)\n",
        "    merged_frame = Dropout(rate_drop_dense)(merged_frame)\n",
        "    merged_frame_dense = Dense(int(number_dense_units/2), activation=activation_function)(merged_frame)\n",
        "    \n",
        "    # merging video-level dense layer output\n",
        "    merged_video = concatenate([video_rgb_dense, video_audio_dense])\n",
        "    merged_video = BatchNormalization()(merged_video)\n",
        "    merged_video = Dropout(rate_drop_dense)(merged_video)\n",
        "    merged_video_dense = Dense(int(number_dense_units/2), activation=activation_function)(merged_video)\n",
        "    \n",
        "    # merging frame-level and video-level dense layer output\n",
        "    merged = concatenate([merged_frame_dense, merged_video_dense])\n",
        "    merged = BatchNormalization()(merged)\n",
        "    merged = Dropout(rate_drop_dense)(merged)\n",
        "     \n",
        "    merged = Dense(number_dense_units, activation=activation_function)(merged)\n",
        "    merged = BatchNormalization()(merged)\n",
        "    merged = Dropout(rate_drop_dense)(merged)\n",
        "    preds = Dense(label_feature_size, activation='sigmoid')(merged)\n",
        "    \n",
        "    model = Model(inputs=[frame_rgb_sequence_input, frame_audio_sequence_input, video_rgb_input, video_audio_input], outputs=preds)\n",
        "    print(model.summary())\n",
        "    model.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc'])\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "    \n",
        "    STAMP = 'lstm_%d_%d_%.2f_%.2f' % (number_lstm_units, number_dense_units, rate_drop_lstm, rate_drop_dense)\n",
        "\n",
        "    checkpoint_dir = 'checkpoints/' + str(int(time.time())) + '/'\n",
        "\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "\n",
        "    bst_model_path = checkpoint_dir + STAMP + '.h5'\n",
        "    model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=False)\n",
        "    tensorboard = TensorBoard(log_dir=checkpoint_dir + \"logs/{}\".format(time.time()))\n",
        "  \n",
        "    model.fit([train_frame_rgb, train_frame_audio, train_video_rgb, train_video_audio], train_labels,\n",
        "              validation_data=([val_frame_rgb, val_frame_audio, val_video_rgb, val_video_audio], val_labels),\n",
        "              epochs=200, batch_size=64, shuffle=False, callbacks=[early_stopping, model_checkpoint, tensorboard])    \n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gddl6Fv1W2Xd"
      },
      "source": [
        "Creating random data set for training \n",
        "\n",
        "Here I am creating a sample dataset of same size and dimension of training sample and will use it to train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xqE7RBZXTLG"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "sample_length = 1000\n",
        "\n",
        "video_rgb = np.random.rand(sample_length, 1024)\n",
        "video_audio = np.random.rand(sample_length, 128)\n",
        "\n",
        "frame_rgb = np.random.rand(sample_length, 10, 1024)\n",
        "frame_audio = np.random.rand(sample_length, 10, 128)\n",
        "\n",
        "# Here I have considered that I have only 10 labels.\n",
        "labels = np.zeros([sample_length,10])\n",
        "for i in range(len(labels)):\n",
        "    j = random.randint(0,9)\n",
        "    labels[i][j] = 1 "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDpN1oTVa9SG"
      },
      "source": [
        "Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-_8gKhSbBQn",
        "outputId": "e45ffc65-e386-4e74-ab0c-bb9df6d9b499"
      },
      "source": [
        "model = create_model(video_rgb, video_audio, frame_rgb, frame_audio, labels)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 10, 1024)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            [(None, 10, 128)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_7 (InputLayer)            [(None, 1024)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_8 (InputLayer)            [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, 200)          900000      input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_3 (Bidirectional) (None, 200)          183200      input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 500)          512500      input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 500)          64500       input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 400)          0           bidirectional_2[0][0]            \n",
            "                                                                 bidirectional_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 1000)         0           dense_6[0][0]                    \n",
            "                                                                 dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 400)          1600        concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 1000)         4000        concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 400)          0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 1000)         0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 500)          200500      dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 500)          500500      dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 1000)         0           dense_8[0][0]                    \n",
            "                                                                 dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 1000)         4000        concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 1000)         0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 1000)         1001000     dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 1000)         4000        dense_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 1000)         0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 10)           10010       dropout_7[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 3,385,810\n",
            "Trainable params: 3,379,010\n",
            "Non-trainable params: 6,800\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "13/13 [==============================] - 16s 463ms/step - loss: 0.9134 - acc: 0.1037 - val_loss: 0.6741 - val_acc: 0.0900\n",
            "Epoch 2/200\n",
            "13/13 [==============================] - 4s 276ms/step - loss: 0.7352 - acc: 0.2800 - val_loss: 0.6268 - val_acc: 0.1100\n",
            "Epoch 3/200\n",
            "13/13 [==============================] - 4s 275ms/step - loss: 0.6079 - acc: 0.5175 - val_loss: 0.5630 - val_acc: 0.1200\n",
            "Epoch 4/200\n",
            "13/13 [==============================] - 4s 284ms/step - loss: 0.5065 - acc: 0.6650 - val_loss: 0.4865 - val_acc: 0.1100\n",
            "Epoch 5/200\n",
            "13/13 [==============================] - 4s 282ms/step - loss: 0.3958 - acc: 0.7937 - val_loss: 0.4313 - val_acc: 0.1200\n",
            "Epoch 6/200\n",
            "13/13 [==============================] - 4s 283ms/step - loss: 0.2961 - acc: 0.9013 - val_loss: 0.3854 - val_acc: 0.1250\n",
            "Epoch 7/200\n",
            "13/13 [==============================] - 4s 281ms/step - loss: 0.2171 - acc: 0.9388 - val_loss: 0.3548 - val_acc: 0.0950\n",
            "Epoch 8/200\n",
            "13/13 [==============================] - 4s 282ms/step - loss: 0.1609 - acc: 0.9650 - val_loss: 0.3450 - val_acc: 0.1100\n",
            "Epoch 9/200\n",
            "13/13 [==============================] - 4s 287ms/step - loss: 0.1231 - acc: 0.9775 - val_loss: 0.3385 - val_acc: 0.1200\n",
            "Epoch 10/200\n",
            "13/13 [==============================] - 4s 273ms/step - loss: 0.0919 - acc: 0.9862 - val_loss: 0.3451 - val_acc: 0.1250\n",
            "Epoch 11/200\n",
            "13/13 [==============================] - 4s 272ms/step - loss: 0.0706 - acc: 0.9975 - val_loss: 0.3608 - val_acc: 0.1300\n",
            "Epoch 12/200\n",
            "13/13 [==============================] - 4s 282ms/step - loss: 0.0573 - acc: 0.9975 - val_loss: 0.3731 - val_acc: 0.1400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNsu_uJFjNAo"
      },
      "source": [
        "#As the model trains, the loss and accuracy metrics are displayed. This model reaches an accuracy of about 0.99 (or 99%) on the training data.#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6-8ZjMsjiDz",
        "outputId": "551a8798-1213-4308-ebda-f8ba039c3bcd"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 10, 1024)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            [(None, 10, 128)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_7 (InputLayer)            [(None, 1024)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_8 (InputLayer)            [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, 200)          900000      input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_3 (Bidirectional) (None, 200)          183200      input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 500)          512500      input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 500)          64500       input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 400)          0           bidirectional_2[0][0]            \n",
            "                                                                 bidirectional_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 1000)         0           dense_6[0][0]                    \n",
            "                                                                 dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 400)          1600        concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 1000)         4000        concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 400)          0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 1000)         0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 500)          200500      dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 500)          500500      dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 1000)         0           dense_8[0][0]                    \n",
            "                                                                 dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 1000)         4000        concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 1000)         0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 1000)         1001000     dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 1000)         4000        dense_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 1000)         0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 10)           10010       dropout_7[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 3,385,810\n",
            "Trainable params: 3,379,010\n",
            "Non-trainable params: 6,800\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3MJYM9ReGjt"
      },
      "source": [
        "Testing with created random test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n916N5qPeHyI",
        "outputId": "fc89df51-45d6-4518-ac78-7da4f06cf8b6"
      },
      "source": [
        "test_video_rgb = np.random.rand(1, 1024)\n",
        "test_video_audio = np.random.rand(1, 128)\n",
        "\n",
        "test_frame_rgb = np.random.rand(1, 10, 1024)\n",
        "test_frame_audio = np.random.rand(1, 10, 128)\n",
        "\n",
        "preds = list(model.predict([test_frame_rgb, test_frame_audio, test_video_rgb, test_video_audio], verbose=1).ravel())\n",
        "index, value = max(enumerate(preds), key=operator.itemgetter(1))\n",
        "print(\"Predicted Label - %s with probability - %s\" % (str(index), str(value)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 997ms/step\n",
            "Predicted Label - 6 with probability - 0.118174404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iojjeQGekFkM"
      },
      "source": [
        "Ploting the perfomance of model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "7VluCo5M6avP",
        "outputId": "79e2605d-bbaa-416f-fa96-72a30898f329"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-a588505d3299>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    JOB_NAME=yt8m_eval_$(date +%Y%m%d_%H%M%S); gcloud --verbosity=debug ai-platform jobs submit training $JOB_NAME --package-path=youtube-8m --module-name=youtube-8m.eval --staging-bucket=$BUCKET_NAME --region=us-east1 --config=youtube-8m/cloudml-gpu.yaml -- --eval_data_pattern='gs://youtube8m-ml/3/frame/validate/validate*.tfrecord' --frame_features --model=FrameLevelLogisticModel --feature_names='rgb,audio' --feature_sizes='1024,128' --train_dir=$BUCKET_NAME/${JOB_TO_EVAL} --segment_labels --run_once=True\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "jFNxhIM3KpyA",
        "outputId": "91913e17-769d-47c4-92bc-e059eef8c393"
      },
      "source": [
        "model.eval()\n",
        "\n",
        "drop_remainder = True\n",
        "\n",
        "scores = model.evaluate(x = (video_rgb, video_audio, frame_rgb, frame_audio), y = labels)\n",
        "print(\"Bi-LSTM:test_loss: %f, accuracy: %f\" % (scores[0], scores[1]) )"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-11c64b910bf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdrop_remainder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvideo_rgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_audio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_rgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_audio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'eval'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "sbut9GNKvFwN",
        "outputId": "91c60642-0133-4faa-fefc-75262b4ad045"
      },
      "source": [
        "from sklearn import metrics\n",
        "print(\"\")\n",
        "print(\"Confusion Matrix:\")\n",
        "confusion_matrix = metrics.confusion_matrix(labels, pred)\n",
        "print(confusion_matrix)\n",
        "normalised_confusion_matrix = np.array(confusion_matrix, dtype=np.float32)/np.sum(confusion_matrix)*100\n",
        "\n",
        "print(\"\")\n",
        "print(\"Confusion matrix (normalised to % of total test data):\")\n",
        "print(normalised_confusion_matrix)\n",
        "print(\"Note: training and testing data is not equally distributed amongst classes, \")\n",
        "print(\"so it is normal that more than a 6th of the data is correctly classifier in the last category.\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Confusion Matrix:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-132-083cb52cf4a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Confusion Matrix:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mconfusion_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnormalised_confusion_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pred' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkAu_aE0_snL"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZuJrrhwfyrF",
        "outputId": "0bfdb033-113b-48e5-c45c-546790ee5977"
      },
      "source": [
        "testPredict = model.predict([test_frame_rgb, test_frame_audio, test_video_rgb, test_video_audio], verbose=1).ravel()\n",
        "trainPredict = model.predict([frame_rgb, frame_audio, video_rgb, video_audio], verbose=1).ravel()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 34ms/step\n",
            "32/32 [==============================] - 1s 44ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "GoXOVViCdmGu",
        "outputId": "eedf8b9d-f3ea-4299-a628-701003c015f4"
      },
      "source": [
        "import numpy as np\n",
        "def prediction(model):\n",
        "    prediction = model.predict([test_frame_rgb, test_frame_audio, test_video_rgb, test_video_audio], verbose=1)\n",
        "    return prediction\n",
        "prediction_bilstm = prediction(model)\n",
        "# Define a function to calculate MAE and RMSE\n",
        "def evaluate_prediction(predictions, actual, model):\n",
        "    errors = predictions - actual\n",
        "    mse = np.square(errors).mean()\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = np.abs(errors).mean()\n",
        "\n",
        "    print('Mean Absolute Error: {:.4f}'.format(mae))\n",
        "    print('Root Mean Square Error: {:.4f}'.format(rmse))\n",
        "    print('')\n",
        "evaluate_prediction(prediction_bilstm, y_test, 'Bidirectional LSTM')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3cfa56b9b1f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_frame_rgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_frame_audio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_video_rgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_video_audio\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprediction_bilstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# Define a function to calculate MAE and RMSE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    }
  ]
}